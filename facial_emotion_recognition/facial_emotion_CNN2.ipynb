{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리 라이브러리\n",
    "import os\n",
    "import os.path as pth\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tensorflow 관련 라이브러리\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, BatchNormalization, PReLU\n",
    "from tensorflow.keras.layers import Flatten, Activation, Dense, GlobalAveragePooling2D, Softmax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# tensorflow에서 사용할 수 없는 기능을 구현하는 기여 저장소\n",
    "from tensorflow_addons import optimizers\n",
    "\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 특정 GPU에 1GB 메모리만 할당하도록 제한\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        \n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=15000)])\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "train_tfrecord_path = pth.join('./data/emotion_crop_re_tf', 'tf_record_train_7.tfrecords')\n",
    "valid_tfrecord_path = pth.join('./data/emotion_crop_re_tf', 'tf_record_valid_7.tfrecords')\n",
    "\n",
    "# BUFFER_SIZE, BATCH_SIZE\n",
    "BUFFER_SIZE = 256\n",
    "BATCH_SIZE = 90\n",
    "NUM_CLASS = 7\n",
    "\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'img_id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = int(target_record['img_id'])\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def prep_func(image, label):\n",
    "    print(type(label))\n",
    "\n",
    "    result_image = image / 255\n",
    "    result_image = tf.image.resize(result_image, (224,224))\n",
    "\n",
    "    onehot_label = tf.one_hot(label, depth=NUM_CLASS)\n",
    "    return result_image, onehot_label\n",
    "\n",
    "    \n",
    "\n",
    "dataset = tf.data.TFRecordDataset(train_tfrecord_path, compression_type='GZIP')\n",
    "dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.TFRecordDataset(valid_tfrecord_path, compression_type='GZIP')\n",
    "valid_dataset = valid_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.shuffle(BUFFER_SIZE)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "valid_dataset = valid_dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience = 5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                            patience = 2,\n",
    "                                            factor = 0.5,\n",
    "                                            min_lr = 1e-7,\n",
    "                                            verbose = 1)\n",
    "\n",
    "model_check = ModelCheckpoint(filepath = './model/emo7_facial_mobile_224_224_PReLU.h5',\n",
    "                              monitor = 'val_loss',\n",
    "                              save_best_only = True)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer True\n",
      "1 ZeroPadding2D True\n",
      "2 Conv2D True\n",
      "3 BatchNormalization True\n",
      "4 ReLU True\n",
      "5 DepthwiseConv2D True\n",
      "6 BatchNormalization True\n",
      "7 ReLU True\n",
      "8 Conv2D True\n",
      "9 BatchNormalization True\n",
      "10 Conv2D True\n",
      "11 BatchNormalization True\n",
      "12 ReLU True\n",
      "13 ZeroPadding2D True\n",
      "14 DepthwiseConv2D True\n",
      "15 BatchNormalization True\n",
      "16 ReLU True\n",
      "17 Conv2D True\n",
      "18 BatchNormalization True\n",
      "19 Conv2D True\n",
      "20 BatchNormalization True\n",
      "21 ReLU True\n",
      "22 DepthwiseConv2D True\n",
      "23 BatchNormalization True\n",
      "24 ReLU True\n",
      "25 Conv2D True\n",
      "26 BatchNormalization True\n",
      "27 Add True\n",
      "28 Conv2D True\n",
      "29 BatchNormalization True\n",
      "30 ReLU True\n",
      "31 ZeroPadding2D True\n",
      "32 DepthwiseConv2D True\n",
      "33 BatchNormalization True\n",
      "34 ReLU True\n",
      "35 Conv2D True\n",
      "36 BatchNormalization True\n",
      "37 Conv2D True\n",
      "38 BatchNormalization True\n",
      "39 ReLU True\n",
      "40 DepthwiseConv2D True\n",
      "41 BatchNormalization True\n",
      "42 ReLU True\n",
      "43 Conv2D True\n",
      "44 BatchNormalization True\n",
      "45 Add True\n",
      "46 Conv2D True\n",
      "47 BatchNormalization True\n",
      "48 ReLU True\n",
      "49 DepthwiseConv2D True\n",
      "50 BatchNormalization True\n",
      "51 ReLU True\n",
      "52 Conv2D True\n",
      "53 BatchNormalization True\n",
      "54 Add True\n",
      "55 Conv2D True\n",
      "56 BatchNormalization True\n",
      "57 ReLU True\n",
      "58 ZeroPadding2D True\n",
      "59 DepthwiseConv2D True\n",
      "60 BatchNormalization True\n",
      "61 ReLU True\n",
      "62 Conv2D True\n",
      "63 BatchNormalization True\n",
      "64 Conv2D True\n",
      "65 BatchNormalization True\n",
      "66 ReLU True\n",
      "67 DepthwiseConv2D True\n",
      "68 BatchNormalization True\n",
      "69 ReLU True\n",
      "70 Conv2D True\n",
      "71 BatchNormalization True\n",
      "72 Add True\n",
      "73 Conv2D True\n",
      "74 BatchNormalization True\n",
      "75 ReLU True\n",
      "76 DepthwiseConv2D True\n",
      "77 BatchNormalization True\n",
      "78 ReLU True\n",
      "79 Conv2D True\n",
      "80 BatchNormalization True\n",
      "81 Add True\n",
      "82 Conv2D True\n",
      "83 BatchNormalization True\n",
      "84 ReLU True\n",
      "85 DepthwiseConv2D True\n",
      "86 BatchNormalization True\n",
      "87 ReLU True\n",
      "88 Conv2D True\n",
      "89 BatchNormalization True\n",
      "90 Add True\n",
      "91 Conv2D True\n",
      "92 BatchNormalization True\n",
      "93 ReLU True\n",
      "94 DepthwiseConv2D True\n",
      "95 BatchNormalization True\n",
      "96 ReLU True\n",
      "97 Conv2D True\n",
      "98 BatchNormalization True\n",
      "99 Conv2D True\n",
      "100 BatchNormalization True\n",
      "101 ReLU True\n",
      "102 DepthwiseConv2D True\n",
      "103 BatchNormalization True\n",
      "104 ReLU True\n",
      "105 Conv2D True\n",
      "106 BatchNormalization True\n",
      "107 Add True\n",
      "108 Conv2D True\n",
      "109 BatchNormalization True\n",
      "110 ReLU True\n",
      "111 DepthwiseConv2D True\n",
      "112 BatchNormalization True\n",
      "113 ReLU True\n",
      "114 Conv2D True\n",
      "115 BatchNormalization True\n",
      "116 Add True\n",
      "117 Conv2D True\n",
      "118 BatchNormalization True\n",
      "119 ReLU True\n",
      "120 ZeroPadding2D True\n",
      "121 DepthwiseConv2D True\n",
      "122 BatchNormalization True\n",
      "123 ReLU True\n",
      "124 Conv2D True\n",
      "125 BatchNormalization True\n",
      "126 Conv2D True\n",
      "127 BatchNormalization True\n",
      "128 ReLU True\n",
      "129 DepthwiseConv2D True\n",
      "130 BatchNormalization True\n",
      "131 ReLU True\n",
      "132 Conv2D True\n",
      "133 BatchNormalization True\n",
      "134 Add True\n",
      "135 Conv2D True\n",
      "136 BatchNormalization True\n",
      "137 ReLU True\n",
      "138 DepthwiseConv2D True\n",
      "139 BatchNormalization True\n",
      "140 ReLU True\n",
      "141 Conv2D True\n",
      "142 BatchNormalization True\n",
      "143 Add True\n",
      "144 Conv2D True\n",
      "145 BatchNormalization True\n",
      "146 ReLU True\n",
      "147 DepthwiseConv2D True\n",
      "148 BatchNormalization True\n",
      "149 ReLU True\n",
      "150 Conv2D True\n",
      "151 BatchNormalization True\n",
      "152 Conv2D True\n",
      "153 BatchNormalization True\n",
      "154 ReLU True\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 8967      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 7)                 7         \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 2,266,986\n",
      "Trainable params: 2,232,860\n",
      "Non-trainable params: 34,126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "mobilenet = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
    "\n",
    "\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "for (i, layer) in enumerate(mobilenet.layers):\n",
    "    print(str(i), layer.__class__.__name__, layer.trainable)\n",
    "    \n",
    "    \n",
    "model = Sequential()\n",
    "model.add(mobilenet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(7))\n",
    "model.add(BatchNormalization())\n",
    "model.add(PReLU())\n",
    "model.add(Softmax(dtype='float32', name='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer True\n",
      "1 Rescaling True\n",
      "2 Normalization True\n",
      "3 ZeroPadding2D True\n",
      "4 Conv2D True\n",
      "5 BatchNormalization True\n",
      "6 Activation True\n",
      "7 DepthwiseConv2D True\n",
      "8 BatchNormalization True\n",
      "9 Activation True\n",
      "10 GlobalAveragePooling2D True\n",
      "11 Reshape True\n",
      "12 Conv2D True\n",
      "13 Conv2D True\n",
      "14 Multiply True\n",
      "15 Conv2D True\n",
      "16 BatchNormalization True\n",
      "17 DepthwiseConv2D True\n",
      "18 BatchNormalization True\n",
      "19 Activation True\n",
      "20 GlobalAveragePooling2D True\n",
      "21 Reshape True\n",
      "22 Conv2D True\n",
      "23 Conv2D True\n",
      "24 Multiply True\n",
      "25 Conv2D True\n",
      "26 BatchNormalization True\n",
      "27 Dropout True\n",
      "28 Add True\n",
      "29 DepthwiseConv2D True\n",
      "30 BatchNormalization True\n",
      "31 Activation True\n",
      "32 GlobalAveragePooling2D True\n",
      "33 Reshape True\n",
      "34 Conv2D True\n",
      "35 Conv2D True\n",
      "36 Multiply True\n",
      "37 Conv2D True\n",
      "38 BatchNormalization True\n",
      "39 Dropout True\n",
      "40 Add True\n",
      "41 Conv2D True\n",
      "42 BatchNormalization True\n",
      "43 Activation True\n",
      "44 ZeroPadding2D True\n",
      "45 DepthwiseConv2D True\n",
      "46 BatchNormalization True\n",
      "47 Activation True\n",
      "48 GlobalAveragePooling2D True\n",
      "49 Reshape True\n",
      "50 Conv2D True\n",
      "51 Conv2D True\n",
      "52 Multiply True\n",
      "53 Conv2D True\n",
      "54 BatchNormalization True\n",
      "55 Conv2D True\n",
      "56 BatchNormalization True\n",
      "57 Activation True\n",
      "58 DepthwiseConv2D True\n",
      "59 BatchNormalization True\n",
      "60 Activation True\n",
      "61 GlobalAveragePooling2D True\n",
      "62 Reshape True\n",
      "63 Conv2D True\n",
      "64 Conv2D True\n",
      "65 Multiply True\n",
      "66 Conv2D True\n",
      "67 BatchNormalization True\n",
      "68 Dropout True\n",
      "69 Add True\n",
      "70 Conv2D True\n",
      "71 BatchNormalization True\n",
      "72 Activation True\n",
      "73 DepthwiseConv2D True\n",
      "74 BatchNormalization True\n",
      "75 Activation True\n",
      "76 GlobalAveragePooling2D True\n",
      "77 Reshape True\n",
      "78 Conv2D True\n",
      "79 Conv2D True\n",
      "80 Multiply True\n",
      "81 Conv2D True\n",
      "82 BatchNormalization True\n",
      "83 Dropout True\n",
      "84 Add True\n",
      "85 Conv2D True\n",
      "86 BatchNormalization True\n",
      "87 Activation True\n",
      "88 DepthwiseConv2D True\n",
      "89 BatchNormalization True\n",
      "90 Activation True\n",
      "91 GlobalAveragePooling2D True\n",
      "92 Reshape True\n",
      "93 Conv2D True\n",
      "94 Conv2D True\n",
      "95 Multiply True\n",
      "96 Conv2D True\n",
      "97 BatchNormalization True\n",
      "98 Dropout True\n",
      "99 Add True\n",
      "100 Conv2D True\n",
      "101 BatchNormalization True\n",
      "102 Activation True\n",
      "103 DepthwiseConv2D True\n",
      "104 BatchNormalization True\n",
      "105 Activation True\n",
      "106 GlobalAveragePooling2D True\n",
      "107 Reshape True\n",
      "108 Conv2D True\n",
      "109 Conv2D True\n",
      "110 Multiply True\n",
      "111 Conv2D True\n",
      "112 BatchNormalization True\n",
      "113 Dropout True\n",
      "114 Add True\n",
      "115 Conv2D True\n",
      "116 BatchNormalization True\n",
      "117 Activation True\n",
      "118 ZeroPadding2D True\n",
      "119 DepthwiseConv2D True\n",
      "120 BatchNormalization True\n",
      "121 Activation True\n",
      "122 GlobalAveragePooling2D True\n",
      "123 Reshape True\n",
      "124 Conv2D True\n",
      "125 Conv2D True\n",
      "126 Multiply True\n",
      "127 Conv2D True\n",
      "128 BatchNormalization True\n",
      "129 Conv2D True\n",
      "130 BatchNormalization True\n",
      "131 Activation True\n",
      "132 DepthwiseConv2D True\n",
      "133 BatchNormalization True\n",
      "134 Activation True\n",
      "135 GlobalAveragePooling2D True\n",
      "136 Reshape True\n",
      "137 Conv2D True\n",
      "138 Conv2D True\n",
      "139 Multiply True\n",
      "140 Conv2D True\n",
      "141 BatchNormalization True\n",
      "142 Dropout True\n",
      "143 Add True\n",
      "144 Conv2D True\n",
      "145 BatchNormalization True\n",
      "146 Activation True\n",
      "147 DepthwiseConv2D True\n",
      "148 BatchNormalization True\n",
      "149 Activation True\n",
      "150 GlobalAveragePooling2D True\n",
      "151 Reshape True\n",
      "152 Conv2D True\n",
      "153 Conv2D True\n",
      "154 Multiply True\n",
      "155 Conv2D True\n",
      "156 BatchNormalization True\n",
      "157 Dropout True\n",
      "158 Add True\n",
      "159 Conv2D True\n",
      "160 BatchNormalization True\n",
      "161 Activation True\n",
      "162 DepthwiseConv2D True\n",
      "163 BatchNormalization True\n",
      "164 Activation True\n",
      "165 GlobalAveragePooling2D True\n",
      "166 Reshape True\n",
      "167 Conv2D True\n",
      "168 Conv2D True\n",
      "169 Multiply True\n",
      "170 Conv2D True\n",
      "171 BatchNormalization True\n",
      "172 Dropout True\n",
      "173 Add True\n",
      "174 Conv2D True\n",
      "175 BatchNormalization True\n",
      "176 Activation True\n",
      "177 DepthwiseConv2D True\n",
      "178 BatchNormalization True\n",
      "179 Activation True\n",
      "180 GlobalAveragePooling2D True\n",
      "181 Reshape True\n",
      "182 Conv2D True\n",
      "183 Conv2D True\n",
      "184 Multiply True\n",
      "185 Conv2D True\n",
      "186 BatchNormalization True\n",
      "187 Dropout True\n",
      "188 Add True\n",
      "189 Conv2D True\n",
      "190 BatchNormalization True\n",
      "191 Activation True\n",
      "192 ZeroPadding2D True\n",
      "193 DepthwiseConv2D True\n",
      "194 BatchNormalization True\n",
      "195 Activation True\n",
      "196 GlobalAveragePooling2D True\n",
      "197 Reshape True\n",
      "198 Conv2D True\n",
      "199 Conv2D True\n",
      "200 Multiply True\n",
      "201 Conv2D True\n",
      "202 BatchNormalization True\n",
      "203 Conv2D True\n",
      "204 BatchNormalization True\n",
      "205 Activation True\n",
      "206 DepthwiseConv2D True\n",
      "207 BatchNormalization True\n",
      "208 Activation True\n",
      "209 GlobalAveragePooling2D True\n",
      "210 Reshape True\n",
      "211 Conv2D True\n",
      "212 Conv2D True\n",
      "213 Multiply True\n",
      "214 Conv2D True\n",
      "215 BatchNormalization True\n",
      "216 Dropout True\n",
      "217 Add True\n",
      "218 Conv2D True\n",
      "219 BatchNormalization True\n",
      "220 Activation True\n",
      "221 DepthwiseConv2D True\n",
      "222 BatchNormalization True\n",
      "223 Activation True\n",
      "224 GlobalAveragePooling2D True\n",
      "225 Reshape True\n",
      "226 Conv2D True\n",
      "227 Conv2D True\n",
      "228 Multiply True\n",
      "229 Conv2D True\n",
      "230 BatchNormalization True\n",
      "231 Dropout True\n",
      "232 Add True\n",
      "233 Conv2D True\n",
      "234 BatchNormalization True\n",
      "235 Activation True\n",
      "236 DepthwiseConv2D True\n",
      "237 BatchNormalization True\n",
      "238 Activation True\n",
      "239 GlobalAveragePooling2D True\n",
      "240 Reshape True\n",
      "241 Conv2D True\n",
      "242 Conv2D True\n",
      "243 Multiply True\n",
      "244 Conv2D True\n",
      "245 BatchNormalization True\n",
      "246 Dropout True\n",
      "247 Add True\n",
      "248 Conv2D True\n",
      "249 BatchNormalization True\n",
      "250 Activation True\n",
      "251 DepthwiseConv2D True\n",
      "252 BatchNormalization True\n",
      "253 Activation True\n",
      "254 GlobalAveragePooling2D True\n",
      "255 Reshape True\n",
      "256 Conv2D True\n",
      "257 Conv2D True\n",
      "258 Multiply True\n",
      "259 Conv2D True\n",
      "260 BatchNormalization True\n",
      "261 Dropout True\n",
      "262 Add True\n",
      "263 Conv2D True\n",
      "264 BatchNormalization True\n",
      "265 Activation True\n",
      "266 DepthwiseConv2D True\n",
      "267 BatchNormalization True\n",
      "268 Activation True\n",
      "269 GlobalAveragePooling2D True\n",
      "270 Reshape True\n",
      "271 Conv2D True\n",
      "272 Conv2D True\n",
      "273 Multiply True\n",
      "274 Conv2D True\n",
      "275 BatchNormalization True\n",
      "276 Dropout True\n",
      "277 Add True\n",
      "278 Conv2D True\n",
      "279 BatchNormalization True\n",
      "280 Activation True\n",
      "281 DepthwiseConv2D True\n",
      "282 BatchNormalization True\n",
      "283 Activation True\n",
      "284 GlobalAveragePooling2D True\n",
      "285 Reshape True\n",
      "286 Conv2D True\n",
      "287 Conv2D True\n",
      "288 Multiply True\n",
      "289 Conv2D True\n",
      "290 BatchNormalization True\n",
      "291 Dropout True\n",
      "292 Add True\n",
      "293 Conv2D True\n",
      "294 BatchNormalization True\n",
      "295 Activation True\n",
      "296 DepthwiseConv2D True\n",
      "297 BatchNormalization True\n",
      "298 Activation True\n",
      "299 GlobalAveragePooling2D True\n",
      "300 Reshape True\n",
      "301 Conv2D True\n",
      "302 Conv2D True\n",
      "303 Multiply True\n",
      "304 Conv2D True\n",
      "305 BatchNormalization True\n",
      "306 Conv2D True\n",
      "307 BatchNormalization True\n",
      "308 Activation True\n",
      "309 DepthwiseConv2D True\n",
      "310 BatchNormalization True\n",
      "311 Activation True\n",
      "312 GlobalAveragePooling2D True\n",
      "313 Reshape True\n",
      "314 Conv2D True\n",
      "315 Conv2D True\n",
      "316 Multiply True\n",
      "317 Conv2D True\n",
      "318 BatchNormalization True\n",
      "319 Dropout True\n",
      "320 Add True\n",
      "321 Conv2D True\n",
      "322 BatchNormalization True\n",
      "323 Activation True\n",
      "324 DepthwiseConv2D True\n",
      "325 BatchNormalization True\n",
      "326 Activation True\n",
      "327 GlobalAveragePooling2D True\n",
      "328 Reshape True\n",
      "329 Conv2D True\n",
      "330 Conv2D True\n",
      "331 Multiply True\n",
      "332 Conv2D True\n",
      "333 BatchNormalization True\n",
      "334 Dropout True\n",
      "335 Add True\n",
      "336 Conv2D True\n",
      "337 BatchNormalization True\n",
      "338 Activation True\n",
      "339 DepthwiseConv2D True\n",
      "340 BatchNormalization True\n",
      "341 Activation True\n",
      "342 GlobalAveragePooling2D True\n",
      "343 Reshape True\n",
      "344 Conv2D True\n",
      "345 Conv2D True\n",
      "346 Multiply True\n",
      "347 Conv2D True\n",
      "348 BatchNormalization True\n",
      "349 Dropout True\n",
      "350 Add True\n",
      "351 Conv2D True\n",
      "352 BatchNormalization True\n",
      "353 Activation True\n",
      "354 DepthwiseConv2D True\n",
      "355 BatchNormalization True\n",
      "356 Activation True\n",
      "357 GlobalAveragePooling2D True\n",
      "358 Reshape True\n",
      "359 Conv2D True\n",
      "360 Conv2D True\n",
      "361 Multiply True\n",
      "362 Conv2D True\n",
      "363 BatchNormalization True\n",
      "364 Dropout True\n",
      "365 Add True\n",
      "366 Conv2D True\n",
      "367 BatchNormalization True\n",
      "368 Activation True\n",
      "369 DepthwiseConv2D True\n",
      "370 BatchNormalization True\n",
      "371 Activation True\n",
      "372 GlobalAveragePooling2D True\n",
      "373 Reshape True\n",
      "374 Conv2D True\n",
      "375 Conv2D True\n",
      "376 Multiply True\n",
      "377 Conv2D True\n",
      "378 BatchNormalization True\n",
      "379 Dropout True\n",
      "380 Add True\n",
      "381 Conv2D True\n",
      "382 BatchNormalization True\n",
      "383 Activation True\n",
      "384 DepthwiseConv2D True\n",
      "385 BatchNormalization True\n",
      "386 Activation True\n",
      "387 GlobalAveragePooling2D True\n",
      "388 Reshape True\n",
      "389 Conv2D True\n",
      "390 Conv2D True\n",
      "391 Multiply True\n",
      "392 Conv2D True\n",
      "393 BatchNormalization True\n",
      "394 Dropout True\n",
      "395 Add True\n",
      "396 Conv2D True\n",
      "397 BatchNormalization True\n",
      "398 Activation True\n",
      "399 ZeroPadding2D True\n",
      "400 DepthwiseConv2D True\n",
      "401 BatchNormalization True\n",
      "402 Activation True\n",
      "403 GlobalAveragePooling2D True\n",
      "404 Reshape True\n",
      "405 Conv2D True\n",
      "406 Conv2D True\n",
      "407 Multiply True\n",
      "408 Conv2D True\n",
      "409 BatchNormalization True\n",
      "410 Conv2D True\n",
      "411 BatchNormalization True\n",
      "412 Activation True\n",
      "413 DepthwiseConv2D True\n",
      "414 BatchNormalization True\n",
      "415 Activation True\n",
      "416 GlobalAveragePooling2D True\n",
      "417 Reshape True\n",
      "418 Conv2D True\n",
      "419 Conv2D True\n",
      "420 Multiply True\n",
      "421 Conv2D True\n",
      "422 BatchNormalization True\n",
      "423 Dropout True\n",
      "424 Add True\n",
      "425 Conv2D True\n",
      "426 BatchNormalization True\n",
      "427 Activation True\n",
      "428 DepthwiseConv2D True\n",
      "429 BatchNormalization True\n",
      "430 Activation True\n",
      "431 GlobalAveragePooling2D True\n",
      "432 Reshape True\n",
      "433 Conv2D True\n",
      "434 Conv2D True\n",
      "435 Multiply True\n",
      "436 Conv2D True\n",
      "437 BatchNormalization True\n",
      "438 Dropout True\n",
      "439 Add True\n",
      "440 Conv2D True\n",
      "441 BatchNormalization True\n",
      "442 Activation True\n",
      "443 DepthwiseConv2D True\n",
      "444 BatchNormalization True\n",
      "445 Activation True\n",
      "446 GlobalAveragePooling2D True\n",
      "447 Reshape True\n",
      "448 Conv2D True\n",
      "449 Conv2D True\n",
      "450 Multiply True\n",
      "451 Conv2D True\n",
      "452 BatchNormalization True\n",
      "453 Dropout True\n",
      "454 Add True\n",
      "455 Conv2D True\n",
      "456 BatchNormalization True\n",
      "457 Activation True\n",
      "458 DepthwiseConv2D True\n",
      "459 BatchNormalization True\n",
      "460 Activation True\n",
      "461 GlobalAveragePooling2D True\n",
      "462 Reshape True\n",
      "463 Conv2D True\n",
      "464 Conv2D True\n",
      "465 Multiply True\n",
      "466 Conv2D True\n",
      "467 BatchNormalization True\n",
      "468 Dropout True\n",
      "469 Add True\n",
      "470 Conv2D True\n",
      "471 BatchNormalization True\n",
      "472 Activation True\n",
      "473 DepthwiseConv2D True\n",
      "474 BatchNormalization True\n",
      "475 Activation True\n",
      "476 GlobalAveragePooling2D True\n",
      "477 Reshape True\n",
      "478 Conv2D True\n",
      "479 Conv2D True\n",
      "480 Multiply True\n",
      "481 Conv2D True\n",
      "482 BatchNormalization True\n",
      "483 Dropout True\n",
      "484 Add True\n",
      "485 Conv2D True\n",
      "486 BatchNormalization True\n",
      "487 Activation True\n",
      "488 DepthwiseConv2D True\n",
      "489 BatchNormalization True\n",
      "490 Activation True\n",
      "491 GlobalAveragePooling2D True\n",
      "492 Reshape True\n",
      "493 Conv2D True\n",
      "494 Conv2D True\n",
      "495 Multiply True\n",
      "496 Conv2D True\n",
      "497 BatchNormalization True\n",
      "498 Dropout True\n",
      "499 Add True\n",
      "500 Conv2D True\n",
      "501 BatchNormalization True\n",
      "502 Activation True\n",
      "503 DepthwiseConv2D True\n",
      "504 BatchNormalization True\n",
      "505 Activation True\n",
      "506 GlobalAveragePooling2D True\n",
      "507 Reshape True\n",
      "508 Conv2D True\n",
      "509 Conv2D True\n",
      "510 Multiply True\n",
      "511 Conv2D True\n",
      "512 BatchNormalization True\n",
      "513 Dropout True\n",
      "514 Add True\n",
      "515 Conv2D True\n",
      "516 BatchNormalization True\n",
      "517 Activation True\n",
      "518 DepthwiseConv2D True\n",
      "519 BatchNormalization True\n",
      "520 Activation True\n",
      "521 GlobalAveragePooling2D True\n",
      "522 Reshape True\n",
      "523 Conv2D True\n",
      "524 Conv2D True\n",
      "525 Multiply True\n",
      "526 Conv2D True\n",
      "527 BatchNormalization True\n",
      "528 Dropout True\n",
      "529 Add True\n",
      "530 Conv2D True\n",
      "531 BatchNormalization True\n",
      "532 Activation True\n",
      "533 DepthwiseConv2D True\n",
      "534 BatchNormalization True\n",
      "535 Activation True\n",
      "536 GlobalAveragePooling2D True\n",
      "537 Reshape True\n",
      "538 Conv2D True\n",
      "539 Conv2D True\n",
      "540 Multiply True\n",
      "541 Conv2D True\n",
      "542 BatchNormalization True\n",
      "543 Conv2D True\n",
      "544 BatchNormalization True\n",
      "545 Activation True\n",
      "546 DepthwiseConv2D True\n",
      "547 BatchNormalization True\n",
      "548 Activation True\n",
      "549 GlobalAveragePooling2D True\n",
      "550 Reshape True\n",
      "551 Conv2D True\n",
      "552 Conv2D True\n",
      "553 Multiply True\n",
      "554 Conv2D True\n",
      "555 BatchNormalization True\n",
      "556 Dropout True\n",
      "557 Add True\n",
      "558 Conv2D True\n",
      "559 BatchNormalization True\n",
      "560 Activation True\n",
      "561 DepthwiseConv2D True\n",
      "562 BatchNormalization True\n",
      "563 Activation True\n",
      "564 GlobalAveragePooling2D True\n",
      "565 Reshape True\n",
      "566 Conv2D True\n",
      "567 Conv2D True\n",
      "568 Multiply True\n",
      "569 Conv2D True\n",
      "570 BatchNormalization True\n",
      "571 Dropout True\n",
      "572 Add True\n",
      "573 Conv2D True\n",
      "574 BatchNormalization True\n",
      "575 Activation True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb5 (Functional)  (None, 9, 9, 2048)        28513527  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 16392     \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 8)                 8         \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 28,538,119\n",
      "Trainable params: 28,361,280\n",
      "Non-trainable params: 176,839\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 시간이 너무 오래 걸림\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB5\n",
    "efnet = EfficientNetB5(weights='imagenet', include_top=False, input_shape=(270,270,3))\n",
    "\n",
    "for layer in efnet.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "for (i, layer) in enumerate(efnet.layers):\n",
    "    print(str(i), layer.__class__.__name__, layer.trainable)\n",
    "    \n",
    "    \n",
    "model = Sequential()\n",
    "model.add(efnet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(8))\n",
    "model.add(PReLU())\n",
    "model.add(Softmax(dtype='float32', name='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 72, 72, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 36, 36, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              44303360  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 5005      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 48,351,765\n",
      "Trainable params: 48,347,013\n",
      "Non-trainable params: 4,752\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## 실패 ## 정확도 10퍼센트대\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(3,3), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RectifiedAdam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "      2/Unknown - 1s 258ms/step - loss: 1.8630 - accuracy: 0.1667WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1957s vs `on_train_batch_end` time: 0.3195s). Check your callbacks.\n",
      "606/606 [==============================] - 365s 602ms/step - loss: 0.5727 - accuracy: 0.8210 - val_loss: 1.0569 - val_accuracy: 0.5454\n",
      "Epoch 2/100\n",
      "606/606 [==============================] - 368s 607ms/step - loss: 0.2564 - accuracy: 0.8731 - val_loss: 0.7687 - val_accuracy: 0.6516\n",
      "Epoch 3/100\n",
      "606/606 [==============================] - 368s 608ms/step - loss: 0.1982 - accuracy: 0.8592 - val_loss: 1.7510 - val_accuracy: 0.2072\n",
      "Epoch 4/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.1905 - accuracy: 0.8551\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "606/606 [==============================] - 368s 608ms/step - loss: 0.1905 - accuracy: 0.8551 - val_loss: 2.0098 - val_accuracy: 0.1312\n",
      "Epoch 5/100\n",
      "606/606 [==============================] - 367s 606ms/step - loss: 0.1293 - accuracy: 0.8714 - val_loss: 1.9428 - val_accuracy: 0.4998\n",
      "Epoch 6/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.8692\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "606/606 [==============================] - 368s 607ms/step - loss: 0.1179 - accuracy: 0.8692 - val_loss: 1.8985 - val_accuracy: 0.4617\n",
      "Epoch 7/100\n",
      "606/606 [==============================] - 366s 604ms/step - loss: 0.0892 - accuracy: 0.8755 - val_loss: 0.4248 - val_accuracy: 0.7507\n",
      "Epoch 8/100\n",
      "606/606 [==============================] - 370s 611ms/step - loss: 0.0777 - accuracy: 0.8782 - val_loss: 0.1135 - val_accuracy: 0.8543\n",
      "Epoch 9/100\n",
      "606/606 [==============================] - 369s 608ms/step - loss: 0.0747 - accuracy: 0.8780 - val_loss: 0.1421 - val_accuracy: 0.8446\n",
      "Epoch 10/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.8763\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "606/606 [==============================] - 369s 608ms/step - loss: 0.0743 - accuracy: 0.8763 - val_loss: 0.1479 - val_accuracy: 0.8382\n",
      "Epoch 11/100\n",
      "606/606 [==============================] - 366s 604ms/step - loss: 0.0605 - accuracy: 0.8828 - val_loss: 0.0630 - val_accuracy: 0.8716\n",
      "Epoch 12/100\n",
      "606/606 [==============================] - 368s 608ms/step - loss: 0.0555 - accuracy: 0.8838 - val_loss: 0.0480 - val_accuracy: 0.8760\n",
      "Epoch 13/100\n",
      "606/606 [==============================] - 367s 606ms/step - loss: 0.0522 - accuracy: 0.8850 - val_loss: 0.0491 - val_accuracy: 0.8759\n",
      "Epoch 14/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.8857\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "606/606 [==============================] - 369s 609ms/step - loss: 0.0501 - accuracy: 0.8857 - val_loss: 0.0437 - val_accuracy: 0.8760\n",
      "Epoch 15/100\n",
      "606/606 [==============================] - 369s 609ms/step - loss: 0.0472 - accuracy: 0.8861 - val_loss: 0.0399 - val_accuracy: 0.8765\n",
      "Epoch 16/100\n",
      "606/606 [==============================] - 369s 610ms/step - loss: 0.0454 - accuracy: 0.8862 - val_loss: 0.0388 - val_accuracy: 0.8769\n",
      "Epoch 17/100\n",
      "606/606 [==============================] - 366s 605ms/step - loss: 0.0437 - accuracy: 0.8869 - val_loss: 0.0387 - val_accuracy: 0.8766\n",
      "Epoch 18/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.8866\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "606/606 [==============================] - 369s 609ms/step - loss: 0.0423 - accuracy: 0.8866 - val_loss: 0.0358 - val_accuracy: 0.8768\n",
      "Epoch 19/100\n",
      "606/606 [==============================] - 371s 612ms/step - loss: 0.0409 - accuracy: 0.8878 - val_loss: 0.0357 - val_accuracy: 0.8770\n",
      "Epoch 20/100\n",
      "606/606 [==============================] - 372s 614ms/step - loss: 0.0400 - accuracy: 0.8899 - val_loss: 0.0345 - val_accuracy: 0.8771\n",
      "Epoch 21/100\n",
      "606/606 [==============================] - 369s 610ms/step - loss: 0.0394 - accuracy: 0.8886 - val_loss: 0.0343 - val_accuracy: 0.8766\n",
      "Epoch 22/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.8899\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "606/606 [==============================] - 366s 604ms/step - loss: 0.0390 - accuracy: 0.8899 - val_loss: 0.0336 - val_accuracy: 0.8768\n",
      "Epoch 23/100\n",
      "606/606 [==============================] - 371s 612ms/step - loss: 0.0381 - accuracy: 0.8918 - val_loss: 0.0328 - val_accuracy: 0.8769\n",
      "Epoch 24/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.8926\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "606/606 [==============================] - 371s 611ms/step - loss: 0.0378 - accuracy: 0.8926 - val_loss: 0.0321 - val_accuracy: 0.8770\n",
      "Epoch 25/100\n",
      "606/606 [==============================] - 369s 609ms/step - loss: 0.0375 - accuracy: 0.8920 - val_loss: 0.0317 - val_accuracy: 0.8770\n",
      "Epoch 26/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.8930\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "606/606 [==============================] - 369s 609ms/step - loss: 0.0373 - accuracy: 0.8930 - val_loss: 0.0300 - val_accuracy: 0.8771\n",
      "Epoch 27/100\n",
      "606/606 [==============================] - 369s 608ms/step - loss: 0.0370 - accuracy: 0.8931 - val_loss: 0.0312 - val_accuracy: 0.8770\n",
      "Epoch 28/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.8922\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "606/606 [==============================] - 369s 609ms/step - loss: 0.0371 - accuracy: 0.8922 - val_loss: 0.0319 - val_accuracy: 0.8770\n",
      "Epoch 29/100\n",
      "606/606 [==============================] - 370s 610ms/step - loss: 0.0370 - accuracy: 0.8927 - val_loss: 0.0312 - val_accuracy: 0.8770\n",
      "Epoch 30/100\n",
      "606/606 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.8932\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "606/606 [==============================] - 368s 607ms/step - loss: 0.0368 - accuracy: 0.8932 - val_loss: 0.0307 - val_accuracy: 0.8770\n",
      "Epoch 31/100\n",
      "606/606 [==============================] - 369s 610ms/step - loss: 0.0369 - accuracy: 0.8938 - val_loss: 0.0316 - val_accuracy: 0.8770\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset,\n",
    "                    epochs=100,\n",
    "                    validation_data=valid_dataset,\n",
    "                    callbacks=callbacks,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_TF2] *",
   "language": "python",
   "name": "conda-env-data_env_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
