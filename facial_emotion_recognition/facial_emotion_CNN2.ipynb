{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리 라이브러리\n",
    "import os\n",
    "import os.path as pth\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tensorflow 관련 라이브러리\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, BatchNormalization, PReLU\n",
    "from tensorflow.keras.layers import Flatten, Activation, Dense, GlobalAveragePooling2D, Softmax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# tensorflow에서 사용할 수 없는 기능을 구현하는 기여 저장소\n",
    "from tensorflow_addons import optimizers\n",
    "\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 특정 GPU에 1GB 메모리만 할당하도록 제한\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        \n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=15000)])\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "train_tfrecord_path = pth.join('./data/emotion_crop_tf', 'tf_record_train.tfrecords')\n",
    "valid_tfrecord_path = pth.join('./data/emotion_crop_tf', 'tf_record_valid.tfrecords')\n",
    "\n",
    "# BUFFER_SIZE, BATCH_SIZE\n",
    "BUFFER_SIZE = 256\n",
    "BATCH_SIZE = 50\n",
    "NUM_CLASS = 8\n",
    "\n",
    "\n",
    "\n",
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'img_id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = int(target_record['img_id'])\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def prep_func(image, label):\n",
    "    print(type(label))\n",
    "\n",
    "    result_image = image / 255\n",
    "    result_image = tf.image.resize(result_image, (224,224))\n",
    "\n",
    "    onehot_label = tf.one_hot(label, depth=NUM_CLASS)\n",
    "    return result_image, onehot_label\n",
    "\n",
    "    \n",
    "\n",
    "dataset = tf.data.TFRecordDataset(train_tfrecord_path, compression_type='GZIP')\n",
    "dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.TFRecordDataset(valid_tfrecord_path, compression_type='GZIP')\n",
    "valid_dataset = valid_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.shuffle(BUFFER_SIZE)\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "valid_dataset = valid_dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience = 5)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                            patience = 2,\n",
    "                                            factor = 0.5,\n",
    "                                            min_lr = 1e-7,\n",
    "                                            verbose = 1)\n",
    "\n",
    "model_check = ModelCheckpoint(filepath = './model/facial_mobile_224_224_PReLU.h5',\n",
    "                              monitor = 'val_loss',\n",
    "                              save_best_only = True)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer True\n",
      "1 ZeroPadding2D True\n",
      "2 Conv2D True\n",
      "3 BatchNormalization True\n",
      "4 ReLU True\n",
      "5 DepthwiseConv2D True\n",
      "6 BatchNormalization True\n",
      "7 ReLU True\n",
      "8 Conv2D True\n",
      "9 BatchNormalization True\n",
      "10 Conv2D True\n",
      "11 BatchNormalization True\n",
      "12 ReLU True\n",
      "13 ZeroPadding2D True\n",
      "14 DepthwiseConv2D True\n",
      "15 BatchNormalization True\n",
      "16 ReLU True\n",
      "17 Conv2D True\n",
      "18 BatchNormalization True\n",
      "19 Conv2D True\n",
      "20 BatchNormalization True\n",
      "21 ReLU True\n",
      "22 DepthwiseConv2D True\n",
      "23 BatchNormalization True\n",
      "24 ReLU True\n",
      "25 Conv2D True\n",
      "26 BatchNormalization True\n",
      "27 Add True\n",
      "28 Conv2D True\n",
      "29 BatchNormalization True\n",
      "30 ReLU True\n",
      "31 ZeroPadding2D True\n",
      "32 DepthwiseConv2D True\n",
      "33 BatchNormalization True\n",
      "34 ReLU True\n",
      "35 Conv2D True\n",
      "36 BatchNormalization True\n",
      "37 Conv2D True\n",
      "38 BatchNormalization True\n",
      "39 ReLU True\n",
      "40 DepthwiseConv2D True\n",
      "41 BatchNormalization True\n",
      "42 ReLU True\n",
      "43 Conv2D True\n",
      "44 BatchNormalization True\n",
      "45 Add True\n",
      "46 Conv2D True\n",
      "47 BatchNormalization True\n",
      "48 ReLU True\n",
      "49 DepthwiseConv2D True\n",
      "50 BatchNormalization True\n",
      "51 ReLU True\n",
      "52 Conv2D True\n",
      "53 BatchNormalization True\n",
      "54 Add True\n",
      "55 Conv2D True\n",
      "56 BatchNormalization True\n",
      "57 ReLU True\n",
      "58 ZeroPadding2D True\n",
      "59 DepthwiseConv2D True\n",
      "60 BatchNormalization True\n",
      "61 ReLU True\n",
      "62 Conv2D True\n",
      "63 BatchNormalization True\n",
      "64 Conv2D True\n",
      "65 BatchNormalization True\n",
      "66 ReLU True\n",
      "67 DepthwiseConv2D True\n",
      "68 BatchNormalization True\n",
      "69 ReLU True\n",
      "70 Conv2D True\n",
      "71 BatchNormalization True\n",
      "72 Add True\n",
      "73 Conv2D True\n",
      "74 BatchNormalization True\n",
      "75 ReLU True\n",
      "76 DepthwiseConv2D True\n",
      "77 BatchNormalization True\n",
      "78 ReLU True\n",
      "79 Conv2D True\n",
      "80 BatchNormalization True\n",
      "81 Add True\n",
      "82 Conv2D True\n",
      "83 BatchNormalization True\n",
      "84 ReLU True\n",
      "85 DepthwiseConv2D True\n",
      "86 BatchNormalization True\n",
      "87 ReLU True\n",
      "88 Conv2D True\n",
      "89 BatchNormalization True\n",
      "90 Add True\n",
      "91 Conv2D True\n",
      "92 BatchNormalization True\n",
      "93 ReLU True\n",
      "94 DepthwiseConv2D True\n",
      "95 BatchNormalization True\n",
      "96 ReLU True\n",
      "97 Conv2D True\n",
      "98 BatchNormalization True\n",
      "99 Conv2D True\n",
      "100 BatchNormalization True\n",
      "101 ReLU True\n",
      "102 DepthwiseConv2D True\n",
      "103 BatchNormalization True\n",
      "104 ReLU True\n",
      "105 Conv2D True\n",
      "106 BatchNormalization True\n",
      "107 Add True\n",
      "108 Conv2D True\n",
      "109 BatchNormalization True\n",
      "110 ReLU True\n",
      "111 DepthwiseConv2D True\n",
      "112 BatchNormalization True\n",
      "113 ReLU True\n",
      "114 Conv2D True\n",
      "115 BatchNormalization True\n",
      "116 Add True\n",
      "117 Conv2D True\n",
      "118 BatchNormalization True\n",
      "119 ReLU True\n",
      "120 ZeroPadding2D True\n",
      "121 DepthwiseConv2D True\n",
      "122 BatchNormalization True\n",
      "123 ReLU True\n",
      "124 Conv2D True\n",
      "125 BatchNormalization True\n",
      "126 Conv2D True\n",
      "127 BatchNormalization True\n",
      "128 ReLU True\n",
      "129 DepthwiseConv2D True\n",
      "130 BatchNormalization True\n",
      "131 ReLU True\n",
      "132 Conv2D True\n",
      "133 BatchNormalization True\n",
      "134 Add True\n",
      "135 Conv2D True\n",
      "136 BatchNormalization True\n",
      "137 ReLU True\n",
      "138 DepthwiseConv2D True\n",
      "139 BatchNormalization True\n",
      "140 ReLU True\n",
      "141 Conv2D True\n",
      "142 BatchNormalization True\n",
      "143 Add True\n",
      "144 Conv2D True\n",
      "145 BatchNormalization True\n",
      "146 ReLU True\n",
      "147 DepthwiseConv2D True\n",
      "148 BatchNormalization True\n",
      "149 ReLU True\n",
      "150 Conv2D True\n",
      "151 BatchNormalization True\n",
      "152 Conv2D True\n",
      "153 BatchNormalization True\n",
      "154 ReLU True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 10248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 8)                 8         \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 2,268,272\n",
      "Trainable params: 2,234,144\n",
      "Non-trainable params: 34,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "mobilenet = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
    "\n",
    "\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "for (i, layer) in enumerate(mobilenet.layers):\n",
    "    print(str(i), layer.__class__.__name__, layer.trainable)\n",
    "    \n",
    "    \n",
    "model = Sequential()\n",
    "model.add(mobilenet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(8))\n",
    "model.add(BatchNormalization())\n",
    "model.add(PReLU())\n",
    "model.add(Softmax(dtype='float32', name='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RectifiedAdam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1503/1503 [==============================] - 609s 405ms/step - loss: 0.5238 - accuracy: 0.7788 - val_loss: 1.1308 - val_accuracy: 0.5495 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "1503/1503 [==============================] - 611s 407ms/step - loss: 0.2951 - accuracy: 0.8168 - val_loss: 1.7646 - val_accuracy: 0.2982 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.8074\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1503/1503 [==============================] - 608s 405ms/step - loss: 0.2715 - accuracy: 0.8074 - val_loss: 3.5765 - val_accuracy: 0.1906 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "1503/1503 [==============================] - 611s 406ms/step - loss: 0.1304 - accuracy: 0.8457 - val_loss: 0.6831 - val_accuracy: 0.7302 - lr: 5.0000e-04\n",
      "Epoch 5/1000\n",
      "1503/1503 [==============================] - 608s 405ms/step - loss: 0.0960 - accuracy: 0.8514 - val_loss: 1.4653 - val_accuracy: 0.5576 - lr: 5.0000e-04\n",
      "Epoch 6/1000\n",
      "1503/1503 [==============================] - 609s 405ms/step - loss: 0.0881 - accuracy: 0.8516 - val_loss: 0.3253 - val_accuracy: 0.7937 - lr: 5.0000e-04\n",
      "Epoch 7/1000\n",
      "1503/1503 [==============================] - 607s 404ms/step - loss: 0.0767 - accuracy: 0.8604 - val_loss: 0.4306 - val_accuracy: 0.7661 - lr: 5.0000e-04\n",
      "Epoch 8/1000\n",
      "1503/1503 [==============================] - 606s 403ms/step - loss: 0.0679 - accuracy: 0.8775 - val_loss: 0.2739 - val_accuracy: 0.7975 - lr: 5.0000e-04\n",
      "Epoch 9/1000\n",
      "1503/1503 [==============================] - 606s 403ms/step - loss: 0.0762 - accuracy: 0.8860 - val_loss: 0.1416 - val_accuracy: 0.8346 - lr: 5.0000e-04\n",
      "Epoch 10/1000\n",
      "1503/1503 [==============================] - 608s 405ms/step - loss: 0.0692 - accuracy: 0.8944 - val_loss: 1.8634 - val_accuracy: 0.5420 - lr: 5.0000e-04\n",
      "Epoch 11/1000\n",
      "1503/1503 [==============================] - 609s 405ms/step - loss: 0.0605 - accuracy: 0.9015 - val_loss: 0.6100 - val_accuracy: 0.8671 - lr: 5.0000e-04\n",
      "Epoch 12/1000\n",
      "1503/1503 [==============================] - 609s 405ms/step - loss: 0.0652 - accuracy: 0.9014 - val_loss: 0.3531 - val_accuracy: 0.7917 - lr: 5.0000e-04\n",
      "Epoch 13/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9020\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1503/1503 [==============================] - 608s 405ms/step - loss: 0.0727 - accuracy: 0.9020 - val_loss: 0.3577 - val_accuracy: 0.7786 - lr: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "1503/1503 [==============================] - 605s 403ms/step - loss: 0.0296 - accuracy: 0.9159 - val_loss: 0.0541 - val_accuracy: 0.9785 - lr: 2.5000e-04\n",
      "Epoch 15/1000\n",
      "1503/1503 [==============================] - 609s 405ms/step - loss: 0.0211 - accuracy: 0.9195 - val_loss: 0.1293 - val_accuracy: 0.9526 - lr: 2.5000e-04\n",
      "Epoch 16/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9192\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1503/1503 [==============================] - 609s 405ms/step - loss: 0.0224 - accuracy: 0.9192 - val_loss: 0.0673 - val_accuracy: 0.9645 - lr: 2.5000e-04\n",
      "Epoch 17/1000\n",
      "1503/1503 [==============================] - 608s 405ms/step - loss: 0.0098 - accuracy: 0.9234 - val_loss: 0.0124 - val_accuracy: 0.9953 - lr: 1.2500e-04\n",
      "Epoch 18/1000\n",
      "1503/1503 [==============================] - 610s 406ms/step - loss: 0.0069 - accuracy: 0.9248 - val_loss: 0.0103 - val_accuracy: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 19/1000\n",
      "1503/1503 [==============================] - 606s 403ms/step - loss: 0.0176 - accuracy: 0.9222 - val_loss: 0.0170 - val_accuracy: 0.9857 - lr: 1.2500e-04\n",
      "Epoch 20/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9261\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1503/1503 [==============================] - 609s 405ms/step - loss: 0.0074 - accuracy: 0.9261 - val_loss: 0.0141 - val_accuracy: 0.9847 - lr: 1.2500e-04\n",
      "Epoch 21/1000\n",
      "1503/1503 [==============================] - 610s 406ms/step - loss: 0.0048 - accuracy: 0.9264 - val_loss: 0.0083 - val_accuracy: 0.8902 - lr: 6.2500e-05\n",
      "Epoch 22/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9256\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "1503/1503 [==============================] - 606s 403ms/step - loss: 0.0066 - accuracy: 0.9256 - val_loss: 0.0145 - val_accuracy: 0.9625 - lr: 6.2500e-05\n",
      "Epoch 23/1000\n",
      "1503/1503 [==============================] - 610s 406ms/step - loss: 0.0043 - accuracy: 0.9265 - val_loss: 0.0067 - val_accuracy: 0.9979 - lr: 3.1250e-05\n",
      "Epoch 24/1000\n",
      "1503/1503 [==============================] - 605s 402ms/step - loss: 0.0027 - accuracy: 0.9270 - val_loss: 0.0062 - val_accuracy: 0.9980 - lr: 3.1250e-05\n",
      "Epoch 25/1000\n",
      "1503/1503 [==============================] - 604s 402ms/step - loss: 0.0028 - accuracy: 0.9259 - val_loss: 0.0061 - val_accuracy: 0.9983 - lr: 3.1250e-05\n",
      "Epoch 26/1000\n",
      "1503/1503 [==============================] - 608s 404ms/step - loss: 0.0023 - accuracy: 0.9254 - val_loss: 0.0060 - val_accuracy: 0.9979 - lr: 3.1250e-05\n",
      "Epoch 27/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9277\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1503/1503 [==============================] - 608s 404ms/step - loss: 0.0020 - accuracy: 0.9277 - val_loss: 0.0068 - val_accuracy: 0.9979 - lr: 3.1250e-05\n",
      "Epoch 28/1000\n",
      "1503/1503 [==============================] - 607s 404ms/step - loss: 0.0018 - accuracy: 0.9251 - val_loss: 0.0056 - val_accuracy: 0.9981 - lr: 1.5625e-05\n",
      "Epoch 29/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9268\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "1503/1503 [==============================] - 605s 403ms/step - loss: 0.0017 - accuracy: 0.9268 - val_loss: 0.0052 - val_accuracy: 0.9982 - lr: 1.5625e-05\n",
      "Epoch 30/1000\n",
      "1503/1503 [==============================] - 605s 403ms/step - loss: 0.0016 - accuracy: 0.9259 - val_loss: 0.0052 - val_accuracy: 0.9985 - lr: 7.8125e-06\n",
      "Epoch 31/1000\n",
      "1503/1503 [==============================] - 607s 404ms/step - loss: 0.0016 - accuracy: 0.9271 - val_loss: 0.0049 - val_accuracy: 0.9985 - lr: 7.8125e-06\n",
      "Epoch 32/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9278\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1503/1503 [==============================] - 608s 405ms/step - loss: 0.0016 - accuracy: 0.9278 - val_loss: 0.0047 - val_accuracy: 0.9986 - lr: 7.8125e-06\n",
      "Epoch 33/1000\n",
      "1503/1503 [==============================] - 609s 406ms/step - loss: 0.0015 - accuracy: 0.9264 - val_loss: 0.0052 - val_accuracy: 0.9983 - lr: 3.9063e-06\n",
      "Epoch 34/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9254\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "1503/1503 [==============================] - 609s 406ms/step - loss: 0.0014 - accuracy: 0.9254 - val_loss: 0.0049 - val_accuracy: 0.9986 - lr: 3.9063e-06\n",
      "Epoch 35/1000\n",
      "1503/1503 [==============================] - 604s 402ms/step - loss: 0.0014 - accuracy: 0.9250 - val_loss: 0.0048 - val_accuracy: 0.9986 - lr: 1.9531e-06\n",
      "Epoch 36/1000\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9265\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "1503/1503 [==============================] - 607s 404ms/step - loss: 0.0036 - accuracy: 0.9265 - val_loss: 0.0048 - val_accuracy: 0.9986 - lr: 1.9531e-06\n",
      "Epoch 37/1000\n",
      "1503/1503 [==============================] - 609s 405ms/step - loss: 0.0015 - accuracy: 0.9265 - val_loss: 0.0048 - val_accuracy: 0.9985 - lr: 9.7656e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset,\n",
    "                    epochs=1000,\n",
    "                    validation_data=valid_dataset,\n",
    "                    callbacks=callbacks,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_TF2] *",
   "language": "python",
   "name": "conda-env-data_env_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
